# 2_create_index.py
"""
Cr√©ation de l'index FAISS avec all-mpnet-base-v2
"""

from pathlib import Path
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

FAISS_INDEX_PATH = Path('faiss_cti_index')


# 2_create_index.py

def get_embedding_model():
    """
    all-mpnet-base-v2 :
    - 768 dimensions
    - 384 tokens max
    - Meilleure qualit√© th√©orique
    """
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-mpnet-base-v2",
        model_kwargs={
            'device': 'cpu',
        },
        encode_kwargs={
            'normalize_embeddings': True,
            'batch_size': 64,    # Plus petit car mod√®le plus lourd
        }
    )


def create_index(documents):
    """Cr√©e et sauvegarde l'index FAISS."""
    print(f"\nüîÑ Cr√©ation de l'index FAISS...")
    print(f"  Mod√®le : all-mpnet-base-v2 (768 dims)")
    print(f"  Documents : {len(documents)}")

    embeddings = get_embedding_model()

    vectorstore = FAISS.from_documents(
        documents=documents,
        embedding=embeddings,
    )

    # Sauvegarde
    vectorstore.save_local(str(FAISS_INDEX_PATH))
    print(f"  ‚úÖ Sauvegard√© : {FAISS_INDEX_PATH}/")

    return vectorstore


def load_index():
    """Charge un index existant."""
    if not FAISS_INDEX_PATH.exists():
        raise FileNotFoundError(
            f"Index non trouv√© : {FAISS_INDEX_PATH}"
        )

    embeddings = get_embedding_model()

    vectorstore = FAISS.load_local(
        str(FAISS_INDEX_PATH),
        embeddings,
        allow_dangerous_deserialization=True,
    )
    print(
        f"‚úÖ Index charg√© : "
        f"{vectorstore.index.ntotal} vecteurs"
    )
    return vectorstore


if __name__ == "__main__":
    from load_documents import load_and_prepare

    docs = load_and_prepare()
    vectorstore = create_index(docs)
    print(f"  Vecteurs : {vectorstore.index.ntotal}")